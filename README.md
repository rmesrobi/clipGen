# clipGen

## Description
This project focuses on extracting meaningful information from long-form videos through a comprehensive data processing pipeline. It begins by transcribing the video content using OpenAI's speech recognition model, Whisper, followed by performing topic modeling with the BERTopic framework.

Once topics are identified, they are labeled using the OpenAI Chat Completion API, ensuring human-readable labels. The project further analyzes these topics, extracting closely related segments of the transcript using sklearn, and then creating corresponding shorter video clips or trailers. Dynamic topic information is then visualized onto each frame using OpenCV.

This project showcases a blend of skills in data engineering, prompt engineering, software engineering, and data science. The modular design of the codebase allows for flexibility in application, with potential for adaptation to other NLP tasks like summarization 

This project showcases a blend of skills in data engineering, data science, prompt engineering, and software engineering, demonstrating creativity and technical proficiency. The modular design of the codebase allows for flexibility in application, ranging from podcast videos to business meetings, with potential for adaptation to other NLP tasks like classification, summarization, and question answering.

## Key Features
- **Transcription of Videos**: Utilizing OpenAI's speech recognition model for accurate video transcriptions.
- **Advanced Topic Modeling**: Employing BERTopic with various, configurable input models for nuanced topic extraction.
- **Human-Readable Labeling**: Enhancing topic labels with OpenAI's Chat Completion API for clarity.
- **Video Clip Generation**: Creating topical video clips based on transcript analysis.
- **Dynamic Topic Visualization**: Displaying topic information with frame-by-frame cosine similarity scores.

## Technologies and Libraries Used
- OpenAI API
- BERTopic
- Transformers
- UMAP
- HDBSCAN
- sklearn
- OpenCV
- nltk
- pydub

## Installation and Running Instructions
Create virtual environment, add video in video-files directory, update configurations in config.conf, and run main.py

## Usage Examples
The image below is a screenshot from an output video generated by this script. In the image you will find the labeled topics and dynamic green bars, which correspond to the cosine similarity of the topic in the frame.

![Sample Output Screenshot](outputs/sample_image.png)